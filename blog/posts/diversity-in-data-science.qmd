---
title: "Just One More Data Center: AI Companies' Addiction to Brute Forcing Development"
author: "Alix Morales"
date: "2025-10-15"
categories: [machine learning, Artificial Intelligence, Opinion]
image: "../data_center_musk.jpeg"
description: "Is AI development doomed to fail at the hands of convenience?"
title-block-banner: "../data_center_musk.jpeg"
---

![Featured Image: James Duncan Davidson](../data_center_musk.jpeg){fig-align="center" width="100%" fig-alt="Alternative text for accessibility"}

## What even is AI?

As more Large Language Models get squeezed out from the babymaking factory that is the world of AI, we must wonder what the hell even is AI? Is there actually such a thing as artificial intelligence? Quite frankly, AI as we know it is not AI. These large language models are simply that, large language models with massive amounts of data that make it particularly adept at predicting sequences of words. There is no intelligence to it. I was speaking to a friend the other day about AI being the biggest fraud of the decade (perhaps too harshly) and he put it quite well when he said that these AI models are fantastic linguistic achievements but that is exactly what they are. These models are not to be taken as anything else, they are remarkable innovations in the world of linguistic understanding, but intelligence they are not.

## So it isn't actually AI as we believed, who cares?
Well these models have certainly proved useful in various applications but their capabilities are highly limited. For starters, the fears of AI leaving us jobless are exagerrated to say the least. AI tools at this stage are simply tools and not capable of replacing human work (yet). Take Deloitte's costly mistake of using AI in their report to the Australian government as ana example. The consulting giant handed over a report with data that the AI hallucinated (made up) and had to cough up the $290k USD loss over a case of gross negligence on their end. This case was likely the result of a consultant cutting corners to meet a deadline and failing to assess the output. Yet, we are told that these models are going to take our jobs? When they are trained to predict strings of text to the users satiation, is it not reasonable to expect the model to be an incompetent employee?

Klarna, a big player in the other massive bubble of buy-now-pay-later credit, has turned from being the "Guinea Pig" for OpenAI to searching for human talent to replace their AI customer service agents. This craze driven by pure and utter speculation is appalling and driving a trend in hiring that will fall flat as ompanies learn that these cost cutting procedures come with financial consequences. Shitty service leads to less customers which leads to less business and you guessed it, less money. Marketing divisions have switched to AI only to find their work to be lazy and uninspired, leading them to hire back experts to restore the mess. Costing them more money then if a human had been in charge all along. Sarah Skidd, a product marketing manager, recalled to the BBC that she was hired to do a job for a client that "was shelling out $2,000 for copy that likely would have ended up being far cheaper had a human just written it in the first place."

## On data centers and brute forcing
So that was my whole argument against the effectiveness of AI and my attempt to reassure you that your job will not be taken by AI and that the attempts to do so are mearly fads that will pass. Now what do we have to say about Data Centers, the crown topic of heated discussions. It appears that no community wants them, they steal power and guzzle water at a rate that rivals niagara's output. So why the rush? Well, capitalistic ideology and greed pushes for more money. The more data centers and more power an AI company has, the more they're worth no? It appears with every new generation of models, the number of parameters used to train that model ahs become the hallmark of performance. But, is this not, mind my language, stupid? How long can you keep throwing GPUs at the problem until it becomes simply unscalable. How much more power and you squeeze out of your models by simply brute forcing your way to a slightly better model? These LLMs do not even behave as brains do, so why have we stopped trying to make AI and pivot to an even better language predictor? 

Money. ðŸ’°

It's about money. Investors and shareholders have dumped billions of dollars into the dream of AI and with a functional product, their focus is on winning the arms race. OpenAI and Anthropic, two leading competitors are floating debt figures in the hundreds of billions and operate on losses of billions quarterly. the money has to end at some point and they need to keep their investors happy. Th issue is, with more data centers and more resources forced into the production of next generation models, the operations only get more expensive and the meager monthly charge for their "plus" services does not even scratch at the surface of the issue? Will they ever be profitable? Not if they keep throwing money and GPUs at the problem. How is it that China's Moonchot Kimi K2 model outperforms all models on the market at the developmental cost of $5 billion USD? Quite simply, the Chinese market is focusing on innovation over profits. Kimi K2 is open source and completely free to download and use. Its goal? Is it to bankrupt America's AI innovation? Is it to assert China's dominance in AI? Or is it simply to create the best models freely and openly for the sake of science? Who knows, but we do know that the large players in the US market are steering a freightliner with a dying motor. That motor will dry up and if steps are not made to correct this addiction with brute frocing development, the AI bubble will collapse and with such great force.

## Takeaways
The lesson is simple, money won't solve your innovation problem OpenAI, Anthropic, etc. And asking the American public to subsidize your data centers that steal power and water from the public does not appear to sit well with the people. Instead of forcing power to come with scale, focus on downscaling models, making them more efficient, and actually trying to create artifical intelligence that mirrors human brains (or not, that's cool too, it is scary stuff). How may they do this? Follow my blog to find out more as I will touch on this later with certain developments I believe may bear fruitful, but for now this shall do for today


### Sources
- Deloitte: https://fortune.com/2025/10/07/deloitte-ai-australia-government-report-hallucinations-technology-290000-refund/
- Klarna: https://futurism.com/klarna-openai-humans-ai-back
- Marketing: https://futurism.com/companies-fixing-ai-replacement-mistakes?utm_term=Futurism%20//%2007.07.25&utm_campaign=Futurism_Actives_Newsletter&utm_source=Sailthru&utm_medium=email
- Kimi: https://www.cnbc.com/2025/11/06/alibaba-backed-moonshot-releases-new-ai-model-kimi-k2-thinking.html
- Link To Try Kimi: https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905