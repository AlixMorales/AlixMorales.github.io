---
title: "Just One More Data Center: AI Companies' Addiction to Brute Forcing Development"
author: "Alix Morales"
date: "2025-10-15"
categories: [machine learning, Artificial Intelligence, Opinion]
image: "../data_center_musk.jpeg"
description: "Is AI development doomed to fail at the hands of convenience?"
#title-block-banner: "../data_center_musk.jpeg"
---

![Featured Image: James Duncan Davidson](../data_center_musk.jpeg){fig-align="center" width="100%" fig-alt="Alternative text for accessibility"}

## What even is AI?

As more large language models are squeezed out of the baby-making factory that is the world of AI, we must wonder what AI is. Is there actually such a thing as artificial intelligence? The truth is, AI as we know it is not AI. These large language models are precisely that: large language models with massive amounts of data, which makes them particularly adept at predicting sequences of words. There is no ‚Äúintelligence‚Äù to it. I was speaking to a friend the other day about AI being vastly overblown and hyped, and he put it quite well when he said that these AI models are fantastic linguistic achievements, but that is precisely what they are. These models are not to be taken as anything else; they are remarkable innovations in the world of linguistic understanding, but a form of ‚Äúintelligence‚Äù they are not.

## So it isn't actually AI as we believed, who cares?
Well, these models have certainly proved useful in various applications, but their capabilities are highly limited. For starters, the fears that AI will leave us jobless are exaggerated; yes, there is a lot of potential for replacement, but at their current stage, AIs are not very capable. AI tools at this stage are simply tools and not capable of replacing human work (yet). Take Deloitte‚Äôs costly mistake of using AI in their report to the Australian government as an example. The consulting giant handed over a report with data that the AI had hallucinated (made up), resulting in a $290k USD loss due to gross negligence. This case could have been the result of a consultant cutting corners to meet a deadline and failing to assess the output. Yet, we are told that these models are going to take our jobs? When they are trained to predict strings of text to the user‚Äôs satisfaction, should we really be surprised when they perform like incompetent employees? UPDATE 12/04/25: Deloitte got caught again... [link](https://fortune.com/2025/11/25/deloitte-caught-fabricated-ai-generated-research-million-dollar-report-canada-government/)

Klarna, a major player in the massive buy-now-pay-later credit bubble, has shifted from being the ‚ÄúGuinea Pig‚Äù for OpenAI to searching for human talent to replace its AI customer service agents. This trend, primarily driven by speculation, represents a troubling pattern in hiring that will ultimately fall flat as companies learn that these cost-cutting measures come with significant financial consequences. Poor service leads to fewer customers, which in turn leads to less business and, you guessed it, less money. Marketing divisions have switched to AI, only to find that their work is lazy and uninspired, leading them to hire experts back to restore the mess. It costs them more money than if a human had been in charge from the beginning. Sarah Skidd, a product marketing manager, recalled to the BBC that she was hired to do a job for a client that ‚Äúwas shelling out $2,000 for copy that likely would have ended up being far cheaper had a human just written it in the first place.‚Äù

## On data centers and brute forcing
That was my argument against the effectiveness of AI and my attempt to reassure you that AI will not take over your job, and that the attempts to do so are fleeting fads that will pass. Now, what do we have to say about data centers, the crown topic of heated discussions? It appears that no community wants them; they steal power and guzzle water at a rate that rivals Niagara‚Äôs output. So why the rush? Greed and the pursuit of profit drive the buildout. The more data centers and more power an AI company has, the more they‚Äôre worth, no? It appears that with every new generation of models, the number of parameters used to train that model has become the hallmark of performance. But is this approach sustainable? How long can you continue to throw GPUs at the problem before it becomes unscalable? How much more performance can you squeeze out by merely brute-forcing your way to a slightly better model? These LLMs do not even behave as brains do, so why have we stopped trying to make AI and pivot to an even better language predictor? 

**Money.** üí∞

It‚Äôs about money. Investors and shareholders have dumped billions of dollars into the dream of AI, and with a functional product in hand, their focus is on winning the arms race. OpenAI and Anthropic, two leading competitors, are reporting debt figures that reach hundreds of billions and operating at quarterly losses of billions of dollars. The money has to end at some point, and they need to keep their investors happy. The issue is that, with more data centers and resources being allocated to the production of next-generation models, the operations become increasingly expensive, and the meager monthly charge for their ‚Äúplus‚Äù services does not even begin to address the issue. Will they ever be profitable? Not if they continue to throw money and GPUs at the problem (however, a recent finding as of December 4, 2025, suggests that Anthropic may turn a profit in 2028). How is it that China‚Äôs Moonshot Kimi K2 model outperforms many models on the market at a developmental cost of $5 billion USD? How? The Chinese market appears to be focusing on innovation over immediate profits. Kimi K2 is open source and completely free to download and use. Its goal? Perhaps to challenge America‚Äôs AI dominance, or maybe simply to create the best models freely and openly for the sake of innovation. Whatever the motivation, the large players in the US market are steering a ship with a finite fuel supply. If steps aren‚Äôt taken to move beyond brute force development, the AI bubble may collapse with considerable force.

## Takeaways
The lesson is straightforward: money won‚Äôt solve your innovation problem, as evidenced by the experiences of OpenAI, Anthropic, and others. Asking the American public to subsidize data centers that consume significant power and water resources doesn‚Äôt sit well with communities. Instead of forcing power to come with scale, focus on downscaling models, making them more efficient, and actually trying to create artificial intelligence that mirrors human brains (or not, that‚Äôs cool too, it is scary stuff). How might they do this? Follow my blog to learn more, as I‚Äôll be discussing this further with certain developments I believe may yield results. For now, this will suffice.


### Sources
- [Deloitte AI Report Refund](https://fortune.com/2025/10/07/deloitte-ai-australia-government-report-hallucinations-technology-290000-refund/)
- [Klarna Replacing AI with Humans](https://futurism.com/klarna-openai-humans-ai-back)
- [Companies Fixing AI Replacement Mistakes](https://futurism.com/companies-fixing-ai-replacement-mistakes?utm_term=Futurism%20//%2007.07.25&utm_campaign=Futurism_Actives_Newsletter&utm_source=Sailthru&utm_medium=email)
- [Alibaba-backed Moonshot Releases Kimi K2 Model](https://www.cnbc.com/2025/11/06/alibaba-backed-moonshot-releases-new-ai-model-kimi-k2-thinking.html)
- [Try Kimi K2 on Hugging Face](https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905)
- [OpenAI Debt Figures](https://www.ft.com/content/5605d086-289e-4b5f-803b-4c13666976a5)
- [Anthropic Profitable by 2028](https://finance.yahoo.com/news/anthropic-poised-beat-openai-profitability-111419930.html)