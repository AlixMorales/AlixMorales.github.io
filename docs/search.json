[
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog! Here I share my very professional opinions on machine learning, AI, and any random things that I may find interesting.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelective Attention and Context-Rot\n\n\n\nmachine learning\n\n\nneural networks\n\n\nresearch\n\n\n\nCan machine learning models remember what they just read?\n\n\n\nAlix Morales\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJust One More Data Center: AI Companies‚Äô Addiction to Brute Forcing Development\n\n\n\nmachine learning\n\n\nArtificial Intelligence\n\n\nOpinion\n\n\n\nIs AI development doomed to fail at the hands of convenience?\n\n\n\nAlix Morales\n\n\nOct 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Data Story\n\n\n\ndata analysis\n\n\nsports\n\n\nstatistics\n\n\n\nHow did I get into data?\n\n\n\nAlix Morales\n\n\nSep 22, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/my-story.html",
    "href": "blog/posts/my-story.html",
    "title": "My Data Story",
    "section": "",
    "text": "Featured Image: Honus Wagner t206 card (The Mona Lisa of Baseball Cards)"
  },
  {
    "objectID": "blog/posts/my-story.html#book-nerd-beginnings",
    "href": "blog/posts/my-story.html#book-nerd-beginnings",
    "title": "My Data Story",
    "section": "Book Nerd Beginnings",
    "text": "Book Nerd Beginnings\nMy data origin story is quite interesting as it came as a result of my love for sports (in particular baseball) and my love for reading. I was in second grade and probably seven or eight years old when I left the library with a cool book. It was themed on baseball and so I was like, why not combine to of my favorite things? Books opened me to worlds of possibilities which I could never be exposed to. Whether the stories took place in the past or in fantastical universes different to ours, I learned a lot of new things. In this instance, I got to learn about baseball cards. The story, in brief, told the stroy of a kid who could travel through time through baseball cards to the time era of the card. In this specific book, he acquired the worlds rarest baseball card (known as our Mona Lisa) and through it travelled back to 1910.\nI finished the book in around 2 days and, by the end of the week, I found myself at Target with all of my birthday money in baseball cards. There is something so satisfying about ripping through wax in the hopes of finding a card of value that nothing else can replicate. After every pack, I would take a look at my players and their statistics on the back. Comparing players, I would create rosters and teams from the players whose stats were the best and eventually play games based off picking statistics from defensive and offensive players a la Pokemon in a dueling manner."
  },
  {
    "objectID": "blog/posts/my-story.html#family-computer-and-baseball-reference",
    "href": "blog/posts/my-story.html#family-computer-and-baseball-reference",
    "title": "My Data Story",
    "section": "Family Computer and Baseball Reference",
    "text": "Family Computer and Baseball Reference\nShortly after, my family got a new computer. Finally, we had a computer that came from after the post dot-com bubble. I could finally search up what the unknown statistics were! I discovered sites like Baseball Almanac and Baseball Reference which were full with just about every statistic recorded in the game and just about all of baseball history. As you can imagine, I spent hours upon hours learning about players, seasons, and advanced statistics. I had memorized so many statistics that I myself became an encyclopedia of sorts. My obsession continued over the years and although it waned at some point, my passion for collecting baseball cards remained.\nNowadays I cannot bring myself to purchase valuable cards but I do own a T206 card made from 1909 to 1912. These cards are known as some of the most desirable sports cards in history. My card is not worth more than $40 but it is from the same type of card as the one in the book that started it all. A tribute to where my collecting frenzy began and a look into the past that created my data future."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, I am Alix Morales!",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n\n\n\n\nHi, I am Alix Morales!\nAlix is a senior majoring in applied math and statistics. As a former athlete, he developed a passion for sports statistics, which led him down the path of data science. He is passionate about machine learning, AI, and its legal implications. From his experience creating mathematical models to drive smarter financial investments to his experience assisting in the classroom, he counts on a deep understanding of data science principles.\nAs a data science intern at Flock Specialty Finance, he utilized mathematical models to enhance the evaluation of potential investment portfolios. Following this experience, he drafted a quantitative report on NFL injury data, alongside a peer and a professor from Emory University, identifying potential factors that affect injury rates. Since then, he has partnered with a researcher at Emory University to work on an entry for a machine learning brain segmentation challenge, utilizing packages such as Monai and scikit-learn.\nAs a teaching assistant for Emory University‚Äôs data science computing course, he developed the ability to break down fundamental data science and computing principles for students. Currently, he serves as a data analytics intern at The Carter Center, where he works on identifying potential use cases for large language models in legal analysis. On campus, Alix is a member of Emory‚Äôs Questbridge Scholar Network and an executive board member for Emory Black and Latin in STEM (BLIS). Alix enjoys spending time outdoors and strumming his guitar in his free time. Specifically, he enjoys playing baseball on the Emory Club Baseball team and roaming through the woods.\nPlease feel free to contact me if you have any questions or would like to discuss potential projects."
  },
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "Resume",
    "section": "",
    "text": "Below is an embedded view of my current resume. You can also download it using the button below.\n\n\n\n\n  \n    ‚ÄÇDownload Resume"
  },
  {
    "objectID": "blog/posts/just-one-more-data-center.html",
    "href": "blog/posts/just-one-more-data-center.html",
    "title": "Just One More Data Center: AI Companies‚Äô Addiction to Brute Forcing Development",
    "section": "",
    "text": "Featured Image: James Duncan Davidson"
  },
  {
    "objectID": "blog/posts/just-one-more-data-center.html#what-even-is-ai",
    "href": "blog/posts/just-one-more-data-center.html#what-even-is-ai",
    "title": "Just One More Data Center: AI Companies‚Äô Addiction to Brute Forcing Development",
    "section": "What even is AI?",
    "text": "What even is AI?\nAs more Large Language Models get squeezed out from the babymaking factory that is the world of AI, we must wonder what the hell even is AI? Is there actually such a thing as artificial intelligence? Quite frankly, AI as we know it is not AI. These large language models are simply that, large language models with massive amounts of data that make it particularly adept at predicting sequences of words. There is no intelligence to it. I was speaking to a friend the other day about AI being the biggest fraud of the decade (perhaps too harshly) and he put it quite well when he said that these AI models are fantastic linguistic achievements but that is exactly what they are. These models are not to be taken as anything else, they are remarkable innovations in the world of linguistic understanding, but intelligence they are not."
  },
  {
    "objectID": "blog/posts/just-one-more-data-center.html#so-it-isnt-actually-ai-as-we-believed-who-cares",
    "href": "blog/posts/just-one-more-data-center.html#so-it-isnt-actually-ai-as-we-believed-who-cares",
    "title": "Just One More Data Center: AI Companies‚Äô Addiction to Brute Forcing Development",
    "section": "So it isn‚Äôt actually AI as we believed, who cares?",
    "text": "So it isn‚Äôt actually AI as we believed, who cares?\nWell these models have certainly proved useful in various applications but their capabilities are highly limited. For starters, the fears of AI leaving us jobless are exagerrated to say the least. AI tools at this stage are simply tools and not capable of replacing human work (yet). Take Deloitte‚Äôs costly mistake of using AI in their report to the Australian government as ana example. The consulting giant handed over a report with data that the AI hallucinated (made up) and had to cough up the $290k USD loss over a case of gross negligence on their end. This case was likely the result of a consultant cutting corners to meet a deadline and failing to assess the output. Yet, we are told that these models are going to take our jobs? When they are trained to predict strings of text to the users satiation, is it not reasonable to expect the model to be an incompetent employee? UPDATE 12/04/25: Deloitte got caught again‚Ä¶ link\nKlarna, a big player in the other massive bubble of buy-now-pay-later credit, has turned from being the ‚ÄúGuinea Pig‚Äù for OpenAI to searching for human talent to replace their AI customer service agents. This craze driven by pure and utter speculation is appalling and driving a trend in hiring that will fall flat as companies learn that these cost cutting procedures come with financial consequences. Shitty service leads to less customers which leads to less business and you guessed it, less money. Marketing divisions have switched to AI only to find their work to be lazy and uninspired, leading them to hire back experts to restore the mess. Costing them more money then if a human had been in charge all along. Sarah Skidd, a product marketing manager, recalled to the BBC that she was hired to do a job for a client that ‚Äúwas shelling out $2,000 for copy that likely would have ended up being far cheaper had a human just written it in the first place.‚Äù"
  },
  {
    "objectID": "blog/posts/just-one-more-data-center.html#on-data-centers-and-brute-forcing",
    "href": "blog/posts/just-one-more-data-center.html#on-data-centers-and-brute-forcing",
    "title": "Just One More Data Center: AI Companies‚Äô Addiction to Brute Forcing Development",
    "section": "On data centers and brute forcing",
    "text": "On data centers and brute forcing\nSo that was my whole argument against the effectiveness of AI and my attempt to reassure you that your job will not be taken by AI and that the attempts to do so are fads that will pass. Now what do we have to say about Data Centers, the crown topic of heated discussions. It appears that no community wants them, they steal power and guzzle water at a rate that rivals niagara‚Äôs output. So why the rush? Well, capitalistic ideology and greed pushes for more money. The more data centers and more power an AI company has, the more they‚Äôre worth no? It appears with every new generation of models, the number of parameters used to train that model ahs become the hallmark of performance. But, is this not, mind my language, stupid? How long can you keep throwing GPUs at the problem until it becomes simply unscalable. How much more power can you squeeze out of your models by simply brute forcing your way to a slightly better model? These LLMs do not even behave as brains do, so why have we stopped trying to make AI and pivot to an even better language predictor?\nMoney. üí∞\nIt‚Äôs about money. Investors and shareholders have dumped billions of dollars into the dream of AI and with a functional product, their focus is on winning the arms race. OpenAI and Anthropic, two leading competitors are floating debt figures that reach hundreds of billions and operate on losses of billions quarterly. the money has to end at some point and they need to keep their investors happy. The issue is, with more data centers and more resources forced into the production of next generation models, the operations only get more expensive and the meager monthly charge for their ‚Äúplus‚Äù services does not even scratch at the surface of the issue? Will they ever be profitable? Not if they keep throwing money and GPUs at the problem. However, a recent finding as of 12/04/25 finds that Anthropic may turn a profit in 2028. How is it that China‚Äôs Moonchot Kimi K2 model outperforms many models on the market at the developmental cost of $5 billion USD? Quite simply, the Chinese market is focusing on innovation over profits. Kimi K2 is open source and completely free to download and use. Its goal? Is it to bankrupt America‚Äôs AI innovation? Is it to assert China‚Äôs dominance in AI? Or is it simply to create the best models freely and openly for the sake of science? Who knows, but we do know that the large players in the US market are steering a freightliner with a dying motor. That fuel will dry up and if steps are not made to correct this addiction with brute frocing development, the AI bubble will collapse and with great force."
  },
  {
    "objectID": "blog/posts/just-one-more-data-center.html#takeaways",
    "href": "blog/posts/just-one-more-data-center.html#takeaways",
    "title": "Just One More Data Center: AI Companies‚Äô Addiction to Brute Forcing Development",
    "section": "Takeaways",
    "text": "Takeaways\nThe lesson is simple, money won‚Äôt solve your innovation problem OpenAI, Anthropic, etc. And asking the American public to subsidize your data centers that steal power and water from the public does not appear to sit well with the people. Instead of forcing power to come with scale, focus on downscaling models, making them more efficient, and actually trying to create artifical intelligence that mirrors human brains (or not, that‚Äôs cool too, it is scary stuff). How may they do this? Follow my blog to find out more as I will touch on this later with certain developments I believe may bear fruitful, but for now this shall do for today\n\nSources\n\nDeloitte AI Report Refund\nKlarna Replacing AI with Humans\nCompanies Fixing AI Replacement Mistakes\nAlibaba-backed Moonshot Releases Kimi K2 Model\nTry Kimi K2 on Hugging Face\nOpenAI Debt Figures\nAnthropic Profitable by 2028"
  },
  {
    "objectID": "blog/posts/selective_attention.html",
    "href": "blog/posts/selective_attention.html",
    "title": "Selective Attention and Context-Rot",
    "section": "",
    "text": "A window to represent our context windows"
  },
  {
    "objectID": "blog/posts/selective_attention.html#context-windows",
    "href": "blog/posts/selective_attention.html#context-windows",
    "title": "Selective Attention and Context-Rot",
    "section": "Context Windows",
    "text": "Context Windows\nWhat is a context window?\nIn layman‚Äôs terms, context windows are the windows that define how much input the LLM can process or even simpler its conversation or task memory. It does so by breaking input into small chunks of text known as tokens. For reference, each token is roughly 4 characters long and is a computable input that the model uses to ‚Äúread.‚Äù Got it? Lovely.\nSo what is the issue?\nYou see, these windows have exploded tremendously since the launch of the fated GPT-3. We went from a context window of 2,048 tokens to a window of 400,000 tokens with GPT-5. Take a second to process just how massive that is. These models can now retain massive amounts of data while being able to actively recall and reference any datapoint. Or so it does on paper. In practice with windows so large, the model is not able to actively remember all details and out of confusion they have the habit of generating made up facts. This act is known as hallucination and when models hallucinate, lazy college students get exposed. Jokes aside, hallucination is a massive issue with AI as the line between truth and fiction blurs. Not only do people believe the hallucinated material and do not bother researching the basis, but also the model becomes very terrible at its job. It trips itself up and becomes borderline useless, its sources sounding more like those of your crazy uncle at the Thanksgiving table. Even worse, and arguably scarier, as models get smarter and more accurate in their outputs, they also become a lot more likely to hallucinate. Like, a lot. From OpenAI‚Äôs first reasoning model (o1) to the latest o3 model the rate of hallucinations DOUBLED."
  },
  {
    "objectID": "blog/posts/selective_attention.html#context-rot",
    "href": "blog/posts/selective_attention.html#context-rot",
    "title": "Selective Attention and Context-Rot",
    "section": "Context Rot",
    "text": "Context Rot\nSo, models are hallucinating a lot and this is an issue since their output is not reliable and possibly made up. This is part of the issue that the idea of context rot gets at. Hong et al.¬†write that as the length of the input context increases, the performance of models decreases. This effect is only amplified when the number of ‚Äúdistractors‚Äù in the the prompt increases. What‚Äôs a distractor? in this case, when we are searching for a fact in a corpus of text, it would be a similarly worded piece of text that may confuse the model if it does not read carefully or consider context. Personally, this was a huge concern for a research project that I did with commercial LLMs in the legal field. With legal provisions necessitating an understanding of legal jargon and the sheer amount of similarly worded text in laws, context rot becomes a real challenge when analyzing large legal texts. Imagine how context rot may affect large companies that use LLMs to replace workers. The performance costs may be very detrimental!"
  },
  {
    "objectID": "blog/posts/selective_attention.html#takeaways",
    "href": "blog/posts/selective_attention.html#takeaways",
    "title": "Selective Attention and Context-Rot",
    "section": "Takeaways",
    "text": "Takeaways\nThe clear takeaway here is that LLMs struggle to understand what they‚Äôre given when the input is quite large. This idea of context rot can be readily applied in the professional world, with a decrease in performance when tasked with larger projects. LLMs excel at precise readings and instruction while struggling to handle large tasks. As we have them currently, no AI model is capable of fully replacing human workers in the workforce. Professionals and executives will soon realize that this mass replacement trend is a fad that will pass and that AI will be understood to be an important tool in the workflow of many professionals.\n\nSources\n\nHallucination: AI hallucinates more frequently as it gets more advanced\nContext Rot Research"
  }
]